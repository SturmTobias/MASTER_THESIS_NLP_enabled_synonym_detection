{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f5683d-b586-4db6-9d8b-3028c6023adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on 7700 distinct labels (700 labels and 10 synonyms per label retrieved) we would get approx. 30 Mio. possible activity label pair combinations. \n",
    "# Therefore strucuture approach 'semantic search pair sampling' based on idea from Thakur et al. 2021 to retrieve high scored synonyms onyl to reduce computational overhead.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b47a45e3-537a-4226-8ff5-cfaf87b55ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import models, losses, util\n",
    "from sentence_transformers import LoggingHandler, SentenceTransformer\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from sentence_transformers.cross_encoder.evaluation import CECorrelationEvaluator\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from sentence_transformers.readers import InputExample\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import csv\n",
    "import torch\n",
    "import tqdm\n",
    "import sys\n",
    "import math\n",
    "import gzip\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48f1f22e-4506-4d22-badd-948e84d5600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = '/home/jupyter-sturm/Archive/01 Datasets/labels_BPIC12_aug.csv'\n",
    "csv = pd.read_csv(path, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "001eb78f-5de7-4688-981d-523a4bfa96cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(csv['augmented_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cf92b52-b828-463b-bb26-16515d674de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Top k similar sentences to be retrieved ####\n",
    "#### Larger the k, bigger the silver dataset ####\n",
    "top_k = 10\n",
    "logging.info(\"Step 2.1: Generate STSbenchmark (silver dataset) using pretrained SBERT \\\n",
    "    model and top-{} semantic search combinations\".format(top_k))\n",
    "\n",
    "\n",
    "silver_data = []\n",
    "#sentences = set()\n",
    "\n",
    "#for sample in gold_samples:\n",
    " #   sentences.update(sample.texts)\n",
    "\n",
    "#sentences = list(sentences) # unique sentences\n",
    "sent2idx = {sentence: idx for idx, sentence in enumerate(sentences)} # storing id and sentence in dictionary\n",
    "#duplicates = set((sent2idx[data.texts[0]], sent2idx[data.texts[1]]) for data in gold_samples) # not to include gold pairs of sentences again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056521e8-94a1-4c11-a48a-4173ea517020",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sent2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c1c31b4-737c-4550-b17d-aa955ac5e873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplicity we use a pretrained model\n",
    "batch_size = 16\n",
    "num_epochs = 1\n",
    "max_seq_length = 128\n",
    "\n",
    "semantic_encoder_path = '/home/jupyter-sturm/output/bi-encoder/qqp_cross_domain_bert-base-uncased-2022-03-17_15-25-31'\n",
    "\n",
    "#semantic_model_name = 'paraphrase-MiniLM-L6-v2'\n",
    "semantic_search_model = SentenceTransformer(semantic_encoder_path)\n",
    "logging.info(\"Encoding unique sentences with semantic search model: {}\".format(semantic_search_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99bf9098-d0b6-4fab-a016-dd7c62d8dcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding all unique sentences present in the training dataset using semantic model\n",
    "embeddings = semantic_search_model.encode(sentences, batch_size=batch_size, convert_to_tensor=True)\n",
    "\n",
    "#logging.info(\"Retrieve top-{} with semantic search model: {}\".format(top_k, semantic_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3914d476-c9ca-4bee-a780-f2ba88c9cf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving top-k sentences given a sentence from the dataset\n",
    "#progress = tqdm.tqdm(unit=\"docs\", total=len(sent2idx))\n",
    "for idx in range(len(sentences)):\n",
    "    sentence_embedding = embeddings[idx]\n",
    "    cos_scores = util.cos_sim(sentence_embedding, embeddings)[0]\n",
    "    cos_scores = cos_scores.cpu()\n",
    "    #progress.update(1)\n",
    "\n",
    "    #torch.topk to find the highest 10 scores\n",
    "    top_results = torch.topk(cos_scores, k=top_k+1)\n",
    "    \n",
    "    for score, iid in zip(top_results[0], top_results[1]):\n",
    "        if iid != idx: #and (iid, idx) not in duplicates:\n",
    "            silver_data.append((sentences[idx], sentences[iid]))\n",
    "            #duplicates.add((idx,iid))\n",
    "\n",
    "#progress.reset()\n",
    "#progress.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a70e8f59-cfa4-4615-8f26-7cb5fea5ef40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('diligence accepted', 'diligence finalized')\n"
     ]
    }
   ],
   "source": [
    "print(silver_data[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
