{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b37a646-8540-4774-8e2d-9371b3ca960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-Trained Cross-Encoder model is trained with STSbenchmark dataset (labeled dataset) to score activirty label pairs retrieved in 03 (semantic search pair sampling) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f1e799d-e034-4ed2-a08f-9aa660272417",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import models, losses, util, LoggingHandler, SentenceTransformer\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from sentence_transformers.cross_encoder.evaluation import CECorrelationEvaluator\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator, BinaryClassificationEvaluator\n",
    "from sentence_transformers.readers import InputExample\n",
    "from datetime import datetime\n",
    "from zipfile import ZipFile\n",
    "import logging\n",
    "import csv\n",
    "import sys\n",
    "import torch\n",
    "import math\n",
    "import gzip\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304e74e6-a4d6-4be6-9e14-d64da4fc8e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Just some code to print debug information to stdout\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "#### /print debug information to stdout\n",
    "\n",
    "#You can specify any huggingface/transformers pre-trained model here, for example, bert-base-uncased, roberta-base, xlm-roberta-base\n",
    "model_name = 'bert-base-uncased'\n",
    "batch_size = 16\n",
    "num_epochs = 1\n",
    "max_seq_length = 128\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "###### Read Datasets ######\n",
    "sts_dataset_path = 'datasets/stsbenchmark.tsv.gz'\n",
    "qqp_dataset_path = 'quora-IR-dataset'\n",
    "\n",
    "\n",
    "# Check if the STSb dataset exsist. If not, download and extract it\n",
    "if not os.path.exists(sts_dataset_path):\n",
    "    util.http_get('https://sbert.net/datasets/stsbenchmark.tsv.gz', sts_dataset_path)\n",
    "\n",
    "\n",
    "# Check if the QQP dataset exists. If not, download and extract\n",
    "if not os.path.exists(qqp_dataset_path):\n",
    "    logging.info(\"Dataset not found. Download\")\n",
    "    zip_save_path = 'quora-IR-dataset.zip'\n",
    "    util.http_get(url='https://sbert.net/datasets/quora-IR-dataset.zip', path=zip_save_path)\n",
    "    with ZipFile(zip_save_path, 'r') as zipIn:\n",
    "        zipIn.extractall(qqp_dataset_path)\n",
    "\n",
    "\n",
    "cross_encoder_path = 'output/cross-encoder/stsb_indomain_'+model_name.replace(\"/\", \"-\")+'-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "#bi_encoder_path = 'output/bi-encoder/qqp_cross_domain_'+model_name.replace(\"/\", \"-\")+'-'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10d99a3-5230-4e0c-b6dd-74bf2e58caa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Cross-encoder (simpletransformers) ######\n",
    "\n",
    "logging.info(\"Loading cross-encoder model: {}\".format(model_name))\n",
    "# Use Huggingface/transformers model (like BERT, RoBERTa, XLNet, XLM-R) for cross-encoder model\n",
    "cross_encoder = CrossEncoder(model_name, num_labels=1)\n",
    "\n",
    "###### Bi-encoder (sentence-transformers) ######\n",
    "\n",
    "#logging.info(\"Loading bi-encoder model: {}\".format(model_name))\n",
    "\n",
    "# Use Huggingface/transformers model (like BERT, RoBERTa, XLNet, XLM-R) for mapping tokens to embeddings\n",
    "word_embedding_model = models.Transformer(model_name, max_seq_length=max_seq_length)\n",
    "\n",
    "# Apply mean pooling to get one fixed sized sentence vector\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(),\n",
    "                               pooling_mode_mean_tokens=True,\n",
    "                               pooling_mode_cls_token=False,\n",
    "                               pooling_mode_max_tokens=False)\n",
    "\n",
    "#bi_encoder = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d770fc-c1ab-4656-9805-f22432f4f1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "#\n",
    "# Step 1: Train cross-encoder model with STSbenchmark (this training is only conducted one time to automatically label the activity labels dataset which is than used to train the final application)\n",
    "#\n",
    "#####################################################\n",
    "\n",
    "logging.info(\"Step 1: Train cross-encoder: {} with STSbenchmark (source dataset)\".format(model_name))\n",
    "\n",
    "gold_samples = [] #training samples\n",
    "dev_samples = []\n",
    "test_samples = []\n",
    "\n",
    "# splitting data into training and test sets\n",
    "\n",
    "with gzip.open(sts_dataset_path, 'rt', encoding='utf8') as fIn:\n",
    "    reader = csv.DictReader(fIn, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "    for row in reader:\n",
    "        score = float(row['score']) / 5.0  # Normalize score to range 0 ... 1\n",
    "\n",
    "        if row['split'] == 'dev':\n",
    "            dev_samples.append(InputExample(texts=[row['sentence1'], row['sentence2']], label=score))\n",
    "        elif row['split'] == 'test':\n",
    "            test_samples.append(InputExample(texts=[row['sentence1'], row['sentence2']], label=score))\n",
    "        else:\n",
    "            #As we want to get symmetric scores, i.e. CrossEncoder(A,B) = CrossEncoder(B,A), we pass both combinations to the train set\n",
    "            gold_samples.append(InputExample(texts=[row['sentence1'], row['sentence2']], label=score))\n",
    "            gold_samples.append(InputExample(texts=[row['sentence2'], row['sentence1']], label=score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70d1a27-bb29-4e03-a7bd-5f596d22698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We wrap gold_samples (which is a List[InputExample]) into a pytorch DataLoader\n",
    "train_dataloader = DataLoader(gold_samples, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# We add an evaluator, which evaluates the performance during training\n",
    "evaluator = CECorrelationEvaluator.from_input_examples(dev_samples, name='sts-dev')\n",
    "\n",
    "# Configure the training\n",
    "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1) #10% of train data for warm-up\n",
    "logging.info(\"Warmup-steps: {}\".format(warmup_steps))\n",
    "\n",
    "# Train the cross-encoder model\n",
    "cross_encoder.fit(train_dataloader=train_dataloader,\n",
    "          evaluator=evaluator,\n",
    "          epochs=num_epochs,\n",
    "          evaluation_steps=1000,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=cross_encoder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3f85b9-cdf0-4490-acfb-6041a0f5db11",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "#\n",
    "# Step 2: Label/Score activity label pairs using the previously trained cross-encoder (BERT) model\n",
    "#\n",
    "##################################################################\n",
    "\n",
    "logging.info(\"Step 2: Label QQP (target dataset) with cross-encoder: {}\".format(model_name))\n",
    "\n",
    "cross_encoder_path_2 = 'output/cross-encoder/stsb_indomain_bert-base-uncased-2022-03-28_11-59-35'\n",
    "\n",
    "cross_encoder = CrossEncoder(cross_encoder_path_2)\n",
    "\n",
    "silver_data = []\n",
    "\n",
    "#with open(os.path.join(qqp_dataset_path, \"classification/train_pairs.tsv\"), encoding='utf8') as fIn:\n",
    " #   reader = csv.DictReader(fIn, delimiter='\\t', quoting=csv.QUOTE_NONE)\n",
    "  #  for row in reader:\n",
    "   #     if row['is_duplicate'] == '1':\n",
    "    #        silver_data.append([row['question1'], row['question2']])\n",
    "    \n",
    "test_data_path = '/home/jupyter-sturm'\n",
    "            \n",
    "with open(os.path.join(test_data_path, \"label_combinations.csv\"), encoding='utf8') as fIn:\n",
    "    reader = csv.DictReader(fIn, delimiter=',', quoting=csv.QUOTE_NONE)\n",
    "    for row in reader: \n",
    "        silver_data.append([row['label1'], row['label2']])\n",
    "\n",
    "silver_scores = cross_encoder.predict(silver_data)\n",
    "\n",
    "# All model predictions should be between [0,1]\n",
    "#assert all(0.0 <= score <= 1.0 for score in silver_scores)\n",
    "\n",
    "#binary_silver_scores = [1 if score >= 0.5 else 0 for score in silver_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7817cedf-9971-41af-8c14-4563bc2ce4b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9496513\n"
     ]
    }
   ],
   "source": [
    "np.argmax(silver_scores)\n",
    "\n",
    "print(silver_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a2317b7-1133-49ab-8ab4-45ac5ea4bfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_scores_matched = list(zip(silver_data, silver_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7ba852af-8d96-430d-9990-3b7477e78dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(labels_scores_matched) \n",
    "df.to_csv('labels_matched.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
